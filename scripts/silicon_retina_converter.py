# -*- coding: utf-8 -*-
"""
Created on Thu Apr  5 13:51:24 2018

@author: Gemma
"""

# =============================================================================
# DIGITAL SILICON RETINA 
# =============================================================================
import tiffcapture as tc 
import numpy as np
from matplotlib import pyplot as plt
import random

# =============================================================================
# LinLog conversion as in the iscas 2012 paper
# The mapping from linear intensity reading (0-255) to log brightness measure is not useful for 
# discrete sample values near zero because log is a very expansive function for positive
# values near zero, resulting in a high number of events caused by sensor noise. 
# To handle these small values, we use a “linlog” mapping which maps linearly up to some value 
# (typically 20) and then maps logarithmically for the rest of the sample values, up to 255."
# =============================================================================

def conversionFunction(x,thr):
    y=np.zeros(x.shape)
    indLin=x<thr
    indLog=np.invert(indLin)
    y[indLin]=x[indLin]
    y[indLog]=np.log(x[indLog]-thr+1)+thr
    return y


# =============================================================================
# STREAM OF EVENTS GENERATOR
#    Read .tiff video
#    For each image it computes the On and Off events as the DVS
    
#    The DVS responds to temporal intensity contrast with a stream of pixel addresses. 
#    Each output event address represents a quantized change of log intensity at a particular pixel 
#    since the last event from that pixel. The address includes a sign bit that distinguishes positive 
#    from negative changes.
    
#    Difference between the current image and the previous saved image, the events
#    are generated if that value go above the threshold. On and Off events have different thresholds
#    return the list of events (x-value,y-value,timestamp: frame-time or linear timestamp,polarity: 1 On/ 0 Off)
# =============================================================================
def siliconRetinaEventsGenerator(filename,thrP,thrN,ThrLinLog,lintime,frameTimeStamp,debug):

# TODO if there is only one value for the tresholds use the same values for thrP,thrN

    tiff = tc.opentiff(filename) #open img
    print("Number of images:", tiff.length)#number of images
    print("Image shape:", tiff.shape)#size of images
    
    timestamp=0#timestamp sets to 0, incremented by 1 for each image
    onEvents=[]
    offEvents=[]
    last_img=np.zeros(tiff.shape, dtype=np.int16)
    events=[]
    
    for img in tiff:
        img=np.int16(img)
                
        conversionFunction(img,ThrLinLog)
            
        #check if the changes surpass a fix threshold (different thresholds for ON and OFF)
        tmp=img-last_img
        onEvents=tmp>thrP
        offEvents=tmp<thrN
        #find the address of the events
        indexOn=np.where(onEvents)
        indexOff=np.where(offEvents)
        numbOn=indexOn[0].shape[0]
        numbOff=indexOff[0].shape[0]
        
        if debug:
            print("On events:",numbOn)
            print("Off events:",numbOff)
        
        if (numbOn==0)&(numbOff==0):
            continue
        
        #Linear Timestamp as in the iscas 2012 paper
        #"The timestamp assigned to each synthetic VSBE event is chosen optionally either to be the frame time 
        #or a time interpolated between the last frame and this one. If the time is set to the frame time, 
        #all events generated by that frame are synchronous, which causes many of the existing event-based
        #processing algorithms which depend on precise event timing to fail. Therefore the optional time 
        #interpolation assigns a timestamp to each separate event within a pixel by linearly interpolating 
        #between the last and current frame timestamps with the total number of events in that pixel. 
        #5 events from one pixel, for instance, will have timestamps separated by 1/5 of the frame interval. 
        #These timestamps serve to desynchronize otherwise simultaneous events but do not increase timing
        #precision, since they are synthetic and the event times are not related to actual visual input."
        

        if lintime:
            timestamp_array=timestamp+np.linspace(0, frameTimeStamp, num=numbOn+numbOff, endpoint=False)
            eventsOn=np.array([indexOn[0],indexOn[1],1*np.ones(numbOn)])
            eventsOff=np.array([indexOff[0],indexOff[1],0*np.ones(numbOff)])
            tmp_events=np.concatenate((eventsOn,eventsOff), axis=1)
            ind = np.lexsort((tmp_events[1],tmp_events[0]))
            [(tmp_events[0][i],tmp_events[1][i],tmp_events[2][i]) for i in ind]
            tmp_events_time=np.append(tmp_events,[timestamp_array],axis=0)
            events.append(np.transpose(tmp_events_time))

            
        else:        
            #create output stream of events
            eventsOn=np.stack([indexOn[0],indexOn[1],1*np.ones(numbOn),timestamp*np.ones(numbOn)],axis=0)
            eventsOff=np.stack([indexOff[0],indexOff[1],0*np.ones(numbOff),timestamp*np.ones(numbOff)],axis=0)
            tmp_events=np.concatenate((eventsOn,eventsOff), axis=1)
            events.append(np.transpose(tmp_events))           
        
        #update last_img
        last_img[onEvents]=img[onEvents]
        last_img[offEvents]=img[offEvents]
            
        timestamp=(1+timestamp)*frameTimeStamp
            
        #DEBUG print images for first 10 cycles
        if ((timestamp<20*frameTimeStamp) & debug):
            plt.figure()
            plt.imshow(img)
            plt.colorbar()
            plt.figure()
            plt.imshow(last_img)
            plt.colorbar()
    
    #convert list in array
    event_array=np.empty(shape=[0,4])
    for i in range(len(events)):
        event_el_array=np.asarray(events[i]) 
        event_array=np.append(event_array,event_el_array,axis=0)
    
    return event_array

# =============================================================================
# ACCUMULATED IMAGES GENERATOR
#     Read .tiff video
#     For each image create ad image of the same size with information of the 
#     ON and OFF spiking pixels
#     Pixels spike when the pixel value goes above the threshold compared to 
#     the previosus frame: -1 means OFF event, 1 ON event and 0 any event
# =============================================================================

def siliconRetinaImagesGenerator(filename,thrP,thrN,refPer,ThrLinLog,frameTimeStamp,debug):
# TODO add refractory period, refresh image, can simulate the refractory 
# period of the retina, in the DVS is a variable parameter
  
    tiff = tc.opentiff(filename) #open img
    tiff_length=tiff.length
    tiff_shape=tiff.shape
    print("Number of images:", tiff_length)#number of images
    print("Image shape:", tiff_shape)#size of images
        
    last_img=np.zeros(tiff_shape, dtype=np.int16)
    DVSvideo=[]
    
    count=0
    
    for img in tiff:
        count=count+1
        img=np.int16(img)
        
        conversionFunction(img,ThrLinLog)
            
        #check if the changes surpass a fix threshold (different thresholds for ON and OFF)
        tmp=img-last_img
        onEvents=tmp>thrP
        offEvents=tmp<thrN
        
        if debug:
            numbOn=np.sum(onEvents)
            numbOff=np.sum(offEvents)
            print("On events:",numbOn)
            print("Off events:",numbOff)
        
        #DVS image
        DVSimg=np.zeros(tiff_shape, dtype=np.int16)
        DVSimg[onEvents]=1
        DVSimg[offEvents]=-1
        DVSvideo.append(DVSimg)
        
        if refPer==0:
            dec_fact=1
            last_img=img
        else:
            dec_fact=np.exp(-count*frameTimeStamp/refPer)
        
            #update last_img
            last_img[onEvents]=img[onEvents]
            last_img[offEvents]=img[offEvents]
            last_img=last_img*dec_fact

        if debug:
            plt.figure()
            plt.imshow(DVSimg)
            plt.colorbar()
            
            if count>30:
                return DVSvideo

    return DVSvideo

def return_xy(index):
    y=(index//3)-1
    x=(index%3)-1
    return x,y

# =============================================================================
# CREATE JITTER IMAGES
# =============================================================================
def jitterImages(filename,numbJitt,debug):
    tiff = tc.opentiff(filename) #open img
    tiff_length=tiff.length
    tiff_shape=tiff.shape
    print("Number of images:", tiff_length)#number of images
    print("Image shape:", tiff_shape)#size of images
    xdim=tiff_shape[0]
    ydim=tiff_shape[1]
    
    frame=3 #numbers of pixels around the image 
    tiff_new_shape=tiff_shape+2*frame*np.ones(len(tiff_shape), dtype=np.int16)
    print("Image new shape:", tiff_new_shape)
    
    JitterVideo=[]
    x0=3
    y0=3
    num_jitter_images=10#number of jitter images
    frame=0
    
    for img in tiff:
        c=0
        mean_value=np.mean(img)
        jitterImg=np.ones(tiff_new_shape, dtype=np.int16)
        jitterImg=mean_value*jitterImg
        
        while (c<num_jitter_images):
            
            idex_value=np.arange(0,9)
            next_pixel=random.choice(idex_value)
            x,y=return_xy(next_pixel)
            x0 += x
            y0 += y
            
            while (x0 < 0)|(x0 >= 6)|(y0 < 0)|(y0 >= 6)|(next_pixel==4):
                p=np.where(idex_value==next_pixel)
                idex_value=np.delete(idex_value,p)
                next_pixel=random.choice(idex_value)
                x,y=return_xy(next_pixel)
                x0 += x
                y0 += y
            
#            if debug:
#                print("x0:",x0)
#                print("y0:",y0)            
            
            jitterImg[x0:x0+xdim, y0:y0+ydim]=img
            c += 1
            
            JitterVideo.append(jitterImg)
            
            if debug:
                plt.figure()
                plt.imshow(jitterImg)
                plt.show()
        
#        print("Frame number:",frame)
        frame += 1

    print("Jitter video len:",len(JitterVideo))
    
    return JitterVideo

def create_video(filename,data):
    print("Create video")
#    size=data[0].shape
#    writer = cv2.VideoWriter(filename,-1,3000,size)
    ir=np.arange(50,60)
    for i in ir:
        frame=data[i]
#        writer.write(frame)
        plt.figure()
        plt.imshow(frame)
        plt.show()
        plt.close()  
    return

# =============================================================================
# MAIN
# =============================================================================
def main(datasetpath):
#    datasetpath='C:/Users/Gemma/Desktop/Tubingen/dataset/movies_for_gemma'
    train_image_path=datasetpath+"/train.tiff"
    test_image_path=datasetpath+"/test.tiff"
    
    thrP=10#positive threshold in DN
    thrN=-10#negative threshold in DN (negative value)
    
    linlog=True #LinLog conversion as in the iscas 2012 paper
    if linlog:
        ThrLinLog=1 #LinLog threshold
    else:
        ThrLinLog=256
    lintime=False #Linear time as in the iscas 2012 paper
    frameTimeStamp=1/30 #.tiff data info time resolution 30Hz=0.033s
#    TODO add refractory period
    refPer=0#refractory period in second 
    
    
    EVENT_STREAM_GENERATOR=False
    EVENT_IMAGES_GENERATOR=False
    CREATE_JITTER_IMAGES=True
    
    debug=True
# =============================================================================
#    EVENT STREAM GENERATOR
# =============================================================================
    if EVENT_STREAM_GENERATOR:
        print("CONVERT TIFF VIDEO IN DVS EVENTS AER RAPPRESENTATION")
        train_DVSevents=siliconRetinaEventsGenerator(train_image_path,thrP,thrN,ThrLinLog,lintime,frameTimeStamp,debug)
        print(train_DVSevents.shape)
        
        test_DVSevents=siliconRetinaEventsGenerator(test_image_path,thrP,thrN,ThrLinLog,lintime,frameTimeStamp,debug)
        print(test_DVSevents.shape)
    
# =============================================================================
#   EVENT IMAGES GENERATOR
# =============================================================================
    if EVENT_IMAGES_GENERATOR:
        print("CONVERT TIFF VIDEO IN DVS IMAGES")
        train_DVSimage=siliconRetinaImagesGenerator(train_image_path,thrP,thrN,refPer,ThrLinLog,frameTimeStamp,debug)
        print("Number of converted images:",len(train_DVSimage))

        test_DVSimage=siliconRetinaImagesGenerator(test_image_path,thrP,thrN,refPer,ThrLinLog,frameTimeStamp,debug)
        print("Number of converted images:",len(test_DVSimage))
        
# =============================================================================
#   CREATE AND SAVE JITTER IMAGES
# =============================================================================
    num_of_jitter_images=10
    if CREATE_JITTER_IMAGES:
        train_jitterimages_path=datasetpath+"/train_jitter.npy"
        test_jitterimages_path=datasetpath+"/test_jitter.npy"
        try: 
            print("load files")
            train_jitterimages=np.load(train_jitterimages_path)
            test_jitterimages=np.load(test_jitterimages_path)
        except IOError:
            print("generate jitter files")
            train_jitterimages=jitterImages(train_image_path,num_of_jitter_images,debug=False)
            np.save(train_jitterimages_path,train_jitterimages)
            
            test_jitterimages=jitterImages(test_image_path,num_of_jitter_images,debug=False)
            np.save(test_jitterimages_path,test_jitterimages)
        
#        create_video(train_jitterimages)
        videoname=datasetpath+"/test_video_short.avi"
        create_video(videoname,test_jitterimages)
    
if __name__ == "__main__":
    datasetpath='C:/Users/Gemma/Desktop/Tubingen/dataset/movies_for_gemma'
    main(datasetpath)